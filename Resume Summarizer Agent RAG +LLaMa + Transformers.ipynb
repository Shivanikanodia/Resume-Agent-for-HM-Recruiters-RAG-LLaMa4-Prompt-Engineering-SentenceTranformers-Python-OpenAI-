{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf9e0a44-54b6-4010-89fd-8e3c3a08c5b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Resume Summarization AI Agent (RAG + LLM)\n",
    "An end-to-end AI pipeline that leverages Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs) on Databricks to generate professional summaries of resumes.\n",
    "\n",
    "#### Technologies Used:\n",
    " - Sentence Transformers for semantic similarity and intelligent chunk retrieval\n",
    "\n",
    " - Databricks-hosted LLaMA for scalable and secure LLM inference\n",
    "\n",
    " - Prompt Engineering to guide the model for clear, high-quality responses\n",
    "\n",
    " - Unity Catalog for distributed access to resume data\n",
    "\n",
    "#### Problem Statement:\n",
    "Recruiters and hiring managers often face the challenge of reviewing hundreds of resumes manually — a process that is both time-consuming and tedious.\n",
    "\n",
    "#### Project Goal:\n",
    "To streamline the recruitment process by generating concise and professional resume summaries using an LLM. The pipeline enhances accuracy and relevance by retrieving only the most semantically important content before passing it to the model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e926ca4-1c7b-4140-ac51-3a9e8cb6a3eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Tools & Technologies:\n",
    "\n",
    "This project is built using the following key components:\n",
    "\n",
    "- Python – Core language for building and orchestrating the pipeline\n",
    "\n",
    "- Sentence Transformers (all-MiniLM-L6-v2) – For semantic search and similarity-based retrieval of relevant resume sections\n",
    "\n",
    "- Databricks LLM Endpoint (LLaMA 4) – Hosted large language model for generating high-quality resume summaries\n",
    "\n",
    "- Apache Spark – To efficiently read and process resumes stored in Unity Catalog Volumes\n",
    "\n",
    "- Prompt Engineering – To craft effective instructions and improve the LLM’s output relevance and clarity\n",
    "\n",
    "- REST API Calls (via requests) – To communicate with the Databricks LLM endpoint for inference  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e194dde-26bc-4595-93ea-304433ba183c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /local_disk0/.ephemeral_nfs/envs/pythonEnv-474abe1a-ddf0-4258-98ee-c1c7f76ffe18/lib/python3.11/site-packages (5.1.0)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-474abe1a-ddf0-4258-98ee-c1c7f76ffe18/lib/python3.11/site-packages (from sentence-transformers) (4.55.0)\nRequirement already satisfied: tqdm in /local_disk0/.ephemeral_nfs/envs/pythonEnv-474abe1a-ddf0-4258-98ee-c1c7f76ffe18/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-474abe1a-ddf0-4258-98ee-c1c7f76ffe18/lib/python3.11/site-packages (from sentence-transformers) (2.8.0)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.11/site-packages (from sentence-transformers) (1.3.0)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.11/site-packages (from sentence-transformers) (1.11.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-474abe1a-ddf0-4258-98ee-c1c7f76ffe18/lib/python3.11/site-packages (from sentence-transformers) (0.34.4)\nRequirement already satisfied: Pillow in /databricks/python3/lib/python3.11/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: typing_extensions>=4.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-474abe1a-ddf0-4258-98ee-c1c7f76ffe18/lib/python3.11/site-packages (from sentence-transformers) (4.14.1)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-474abe1a-ddf0-4258-98ee-c1c7f76ffe18/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\nRequirement already satisfied: packaging>=20.9 in /databricks/python3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.31.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-474abe1a-ddf0-4258-98ee-c1c7f76ffe18/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.7)\nRequirement already satisfied: sympy>=1.13.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-474abe1a-ddf0-4258-98ee-c1c7f76ffe18/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\nRequirement already satisfied: networkx in /local_disk0/.ephemeral_nfs/envs/pythonEnv-474abe1a-ddf0-4258-98ee-c1c7f76ffe18/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\nRequirement already satisfied: jinja2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-474abe1a-ddf0-4258-98ee-c1c7f76ffe18/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: numpy>=1.17 in /databricks/python3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.23.5)\nRequirement already satisfied: regex!=2019.12.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-474abe1a-ddf0-4258-98ee-c1c7f76ffe18/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.34)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-474abe1a-ddf0-4258-98ee-c1c7f76ffe18/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\nRequirement already satisfied: safetensors>=0.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-474abe1a-ddf0-4258-98ee-c1c7f76ffe18/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: joblib>=1.1.1 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-474abe1a-ddf0-4258-98ee-c1c7f76ffe18/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-474abe1a-ddf0-4258-98ee-c1c7f76ffe18/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2023.7.22)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# resume_summary_pipeline.py\n",
    "\n",
    "%pip install sentence-transformers\n",
    "\n",
    "from pathlib import Path\n",
    "import textwrap\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b74659dd-be47-4831-8a98-dd45d1f9d4fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Read and Chunk Resume: \n",
    "\n",
    "LLMs perform better with concise inputs. We chunk long resumes into small parts (~800 chars) to be later searched semantically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b2b685c-3f53-470a-a548-34472330d061",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_and_chunk_resume(path, width=800):\n",
    "    text = Path(path).read_text()\n",
    "    return textwrap.wrap(text, width=width)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "233435e8-74db-4872-bd5f-317876d31e99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "***Path(path).read_text(),** reads the content of the file at the specified path and uses pathlib.Path for cross-platform reliability.*\n",
    "\n",
    "***textwrap.wrap(text, width=800),** Splits the long resume string into chunks of **~800 characters** and Avoids cutting off mid-word and improves token management for LLMs.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0568c086-c88f-4646-91c9-4b97a5cc5239",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Generate Embeddings:\n",
    "\n",
    "Embeddings converts chunks into high-dimensional vectors so we can find semantically similar text based on a query.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cddcf01-3c50-4dce-9de7-2191b74292f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def get_embeddings(chunks, model_name=\"all-MiniLM-L6-v2\"):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    embeddings = model.encode(chunks)\n",
    "    return embeddings, model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9485bc6f-8bca-4801-9750-3f1b84c8777f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To convert text chunks into dense vector representations, a pretrained transformer model is loaded using **SentenceTransformer(model_name).** For example, the **\"all-MiniLM-L6-v2\"** model is an efficient choice that generates 384-dimensional embeddings. \n",
    "\n",
    "The **model.encode(chunks)** function takes a list of text chunks and converts each into a dense vector of floating-point numbers that capture the semantic meaning of the text. \n",
    "\n",
    "This process returns two outputs: embeddings, which is the list of vector representations (one per chunk), and the model itself, which can be reused later for embedding query. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed4267a8-dc3f-48f0-8719-fa0060bd9bab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Semantic Retrieval: \n",
    "\n",
    "\n",
    "Finds the most relevant text chunks from a list based on semantic similarity to a given query using cosine similarity, saving tokens and improving accuracy. \n",
    "\n",
    "*Steps:**\n",
    "  1. Encodes the query into an embedding vector.\n",
    "  2. Calculates cosine similarity between the query vector and all chunk embeddings.\n",
    "  3. Sorts the chunks by similarity score in descending order.\n",
    "  4. Returns the top-k most relevant chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19b837a4-0e50-43a8-a95a-91e5d9880ec5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_top_k_chunks(query, chunks, embeddings, model, top_k=3):\n",
    "    query_embedding = model.encode([query])[0]\n",
    "    similarities = cosine_similarity([query_embedding], embeddings)[0]\n",
    "    top_indices = similarities.argsort()[::-1][:top_k]\n",
    "    return [chunks[i] for i in top_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5f1aac8-501d-42d3-9cdd-831c92eb7123",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Read Resume from Unity Catalog via Spark: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32496153-c393-45fb-8648-9906d17f368c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_resume_from_unity(file_path):\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    df = spark.read.text(file_path)\n",
    "    return \"\\n\".join(row.value for row in df.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e26c0cfe-8003-453c-95a6-fca5b07fa9f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Calling Databricks LLM: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ff0524b-34f4-484a-864d-e4e6674c0d58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0be43b20-6c5f-487c-91d3-d0ab387833c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def call_databricks_llm(prompt, model=\"databricks-llama-4-maverick\", max_tokens=500):\n",
    "    \n",
    "    os.environ[\"DATABRICKS_HOST\"] = DATABRICKS_HOST\n",
    "    os.environ[\"DATABRICKS_TOKEN\"] = DATABRICKS_TOKEN\n",
    "\n",
    "    api_url = f\"https://dbc-7412fe25-6807.cloud.databricks.com/serving-endpoints/databricks-llama-4-maverick/invocations\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {os.environ['DATABRICKS_TOKEN']}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes resumes.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens\n",
    "    }\n",
    "\n",
    "    response = requests.post(api_url, headers=headers, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        print(\"\uD83D\uDD0D Response JSON:\", response_json)  # TEMP DEBUG LINE\n",
    "\n",
    "        # Try common response formats\n",
    "        if \"predictions\" in response_json:\n",
    "            return response_json[\"predictions\"][0][\"message\"][\"content\"]\n",
    "        elif \"choices\" in response_json:\n",
    "            return response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "        elif \"data\" in response_json:\n",
    "            return response_json[\"data\"][\"message\"]\n",
    "        else:\n",
    "            raise Exception(f\"❌ Unknown response structure: {response_json}\")\n",
    "    else:\n",
    "        raise Exception(f\"❌ Request failed with status code {response.status_code}: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ecdef29-bcfe-4f86-bba5-d8187016d70d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "This script interacts with a Databricks-hosted large language model (LLM) by sending a prompt and receiving a summarized response. The API URL is constructed dynamically using the model name to ensure the request reaches the correct endpoint. The payload follows the OpenAI-style chat format, which includes a system message to set the assistant's behavior and a user message containing the actual prompt. The max_tokens parameter is used to limit the length of the model's response, ensuring it remains concise and controlled. Finally, the requests.post() function is used to make the HTTP request, sending the payload and headers to the LLM endpoint and retrieving the generated output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9fc4e1b-0b86-4b41-8452-60f52ceb60b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Format Prompt with Prompt Engineering:\n",
    "\n",
    "This function is designed to build a well-structured prompt that will be sent to a Large Language Model (LLM) for resume summarization. \n",
    "\n",
    "It takes two main inputs: context, which consists of relevant resume chunks retrieved through semantic search, and query, which is the specific instruction or question for the model to answer (e.g., \"Summarize this candidate’s experience\"). \n",
    "\n",
    "The goal is to format these inputs into a cohesive and clear prompt that guides the LLM to produce accurate, concise, and relevant summaries. \n",
    "\n",
    "The structured format helps ensure the model focuses only on the important information from the resume while following the desired task.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "189cd9f2-cf22-43d3-8e76-18a8448e69e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def format_prompt(context, query):\n",
    "    return f\"\"\"\n",
    "[System Role]\n",
    "You are a Resume Summarization Agent built to support hiring managers and recruiters by extracting key candidate insights from resumes — all in under 3 seconds.\n",
    "\n",
    "You understand:\n",
    "- Resume structure (Experience, Skills, Education, Certifications)\n",
    "- Tech roles and industry-specific terminology\n",
    "- Professional, recruiter-facing tone\n",
    "\n",
    "Goal:\n",
    "Generate a concise, structured summary that enables rapid screening and reduces time spent reading full resumes.\n",
    "\n",
    "Resume:\n",
    "{context}\n",
    "\n",
    "Task:\n",
    "Summarize the candidate profile using these guidelines:\n",
    "\n",
    "1. Include Job titles, companies, industries, and total experience.\n",
    "2. Highlight technical tools, platforms, or domains. \n",
    "3. Mention notable accomplishments or quantifiable impact.\n",
    "4. Include relevant responsibilities, avoiding overly detailed or repetitive lines.\n",
    "5. Use clear bullet points for skimming efficiency.\n",
    "\n",
    "Constraints:\n",
    "- Avoid hallucination or extrapolation. \n",
    "- Do **not** add something which is not in resume. \n",
    "- Maintain a confident and neutral tone\n",
    "\n",
    "\uD83D\uDCE4 Output Format:\n",
    "- Bullet points only, no introduction or conclusion\n",
    "\n",
    "\uD83D\uDD0D Hiring Manager Query:\n",
    "Now respond to this specific question based on the resume above:\n",
    "**\"{query}\"**\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d6c19f2-5821-4366-b3bf-17473715aa0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def summarize_resume(file_path_txt, query=\" How many years of experience does she have in python, sql, ML, Databricks and business problems \"):\n",
    "    chunks = read_and_chunk_resume(file_path_txt)\n",
    "    embeddings, model = get_embeddings(chunks)\n",
    "    top_chunks = get_top_k_chunks(query, chunks, embeddings, model)\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "    prompt = format_prompt(context, query)\n",
    "    summary = call_databricks_llm(prompt)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d850e70-3b01-46c6-a809-777d5006f6ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD0D Response JSON: {'id': 'chatcmpl_32dd2ceb-d8b4-4371-94de-dc5453b5edb9', 'object': 'chat.completion', 'created': 1754972153, 'model': 'meta-llama-4-maverick-040225', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '• 2.5 years of experience in Data Science, with proficiency in Python and ML\\n• Utilized Python libraries like Pandas, NumPy, and Scikit-learn for data analysis\\n• Worked with SQL, optimizing complex queries by restructuring joins and creating indexes\\n• Experienced in Databricks, building and managing clusters to run MLflow experiments\\n• Applied ML models to drive business outcomes, such as saving $300K in hiring costs\\n• 3 years of experience in Business Consulting, with a background in Business Analytics\\n• Demonstrated ability to drive data-driven decision-making, resulting in a 20% improvement\\n• Proficient in using various tools and technologies to solve business problems'}, 'finish_reason': 'stop', 'logprobs': None}], 'usage': {'prompt_tokens': 863, 'completion_tokens': 141, 'total_tokens': 1004}}\n• 2.5 years of experience in Data Science, with proficiency in Python and ML\n• Utilized Python libraries like Pandas, NumPy, and Scikit-learn for data analysis\n• Worked with SQL, optimizing complex queries by restructuring joins and creating indexes\n• Experienced in Databricks, building and managing clusters to run MLflow experiments\n• Applied ML models to drive business outcomes, such as saving $300K in hiring costs\n• 3 years of experience in Business Consulting, with a background in Business Analytics\n• Demonstrated ability to drive data-driven decision-making, resulting in a 20% improvement\n• Proficient in using various tools and technologies to solve business problems\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import textwrap\n",
    "import os \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result = summarize_resume(\"/Volumes/workspace/default/default_resume/Shivani_Kanodia.txt\")\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Resume Summarizer Agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

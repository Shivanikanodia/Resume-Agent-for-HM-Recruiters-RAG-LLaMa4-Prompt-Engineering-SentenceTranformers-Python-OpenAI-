### Resume Summarization AI Agent (RAG + LLM)

An end-to-end AI pipeline built on Databricks that leverages Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs) to automatically generate professional resume summaries.

#### ğŸ“Œ Problem Statement:

Recruiters and hiring managers often have to manually review hundreds of resumes â€” a time-consuming and error-prone process. This project aims to streamline recruitment by automatically creating concise, professional summaries from resumes, ensuring only the most relevant and important content is highlighted.

#### ğŸ¯ Project Goals:

Reduce manual effort in resume screening.

Generate clear, concise, and relevant summaries.

Retrieve only the most important sections from resumes using semantic similarity before LLM processing.

#### ğŸ› ï¸ Technologies Used

- Python â€“ Core language for building and orchestrating the pipeline.

- Sentence Transformers (all-MiniLM-L6-v2) â€“ For semantic search and intelligent chunk retrieval.

- Databricks LLM Endpoint (LLaMA 4) â€“ Hosted Large Language Model for high-quality summarization.

- Apache Spark + Unity Catalog â€“ Distributed processing and secure access to resume data.

- Prompt Engineering â€“ Optimized instructions for accurate and context-aware model output.

- REST API Calls â€“ Integration with Databricks LLM endpoints.

- Databricks Notebooks â€“ For pipeline execution and orchestration.

#### âš™ï¸ How It Works

1. Data Loading â€“ Resumes are read from Unity Catalog Volumes using Apache Spark.

2. Chunking & Embedding â€“ Each resume is split into chunks, embedded using Sentence Transformers.

3. Semantic Retrieval â€“ Relevant chunks are retrieved based on query similarity.

4. Prompt Construction â€“ Retrieved content is passed into a carefully engineered LLM prompt.

5. Summary Generation â€“ LLaMA 4 (Databricks-hosted) generates the final professional summary.

6. Output Storage â€“ Summaries are saved back to Databricks for recruiter access.

#### ğŸ“‚ Project Structure
Resume Summarizer Agent (3).py   # Main Databricks notebook script

#### ğŸš€ Installation

Make sure you are running inside a Databricks Notebook with the following installed:

%pip install sentence-transformers

â–¶ï¸ Usage

Upload your resumes to a Unity Catalog Volume.

Open the notebook in Databricks.

Configure:

LLM endpoint URL & token

Resume data path in Unity Catalog

Run all cells â€” summaries will be generated and stored.

ğŸ”‘ Example Output

Input:

[Resume text...]


Output:

"Results-driven data analyst with 5 years of experience in..."

ğŸ“ˆ Benefits

Cuts resume review time drastically.

Improves accuracy & relevance of summaries.

Can be scaled to thousands of resumes.

ğŸ“œ License

This project is intended for educational and internal enterprise use.

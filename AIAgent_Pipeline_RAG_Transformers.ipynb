{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf9e0a44-54b6-4010-89fd-8e3c3a08c5b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####  Resume Summarization AI Agent (RAG + LLM):\n",
    "An end-to-end pipeline that uses Retrieval-Augmented Generation (RAG), Sentence Transformers, Re-ranking and an LLM to generate concise, role-aware candidate resume summaries.\n",
    "\n",
    "####  Problem:\n",
    "Recruiters and hiring managers often review hundreds of resumes manually—slow, inconsistent, and error-prone. This agent extracts the information that actually matters to hiring teams and produces fast, consistent summaries.\n",
    "\n",
    "####  Goal:\n",
    "Serve Hiring Managers and Recruiters across functions (Engineering, Global Functions, Professional Services, etc.). Let users query large resume sets by skills, experience, and team fit. Reduce time-to-screen by surfacing the most relevant candidates and summaries.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3b7a798-a881-434f-8cbf-fb3d9e312f15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## How It Works (Architecture):\n",
    "\n",
    " - Data Loading: Read resumes stored in Unity Catalog Volumes / Delta.\n",
    "\n",
    "- Chunking & Embeddings: Split resumes into ~800-character chunks.\n",
    "\n",
    "- Embed with all-MiniLM-L6-v2 (384-dim) via SentenceTransformer.\n",
    "\n",
    "- Semantic Retrieval (Recall): Cosine similarity over embeddings to fetch top-k relevant chunks (FAISS or equivalent index recommended).\n",
    "\n",
    "- Re-ranking (Precision): Cross-encoder scores (query, chunk) pairs and reorders the retrieved set to keep the most relevant passages.\n",
    "\n",
    "- Prompt Construction: Insert top chunks into a concise, instruction-driven prompt with rules/constraints (focus on role fit, impact, skills, recency).\n",
    "\n",
    "- LLM Generation: Call Databricks-hosted Llama endpoint to produce the final summary/answer, REST API Calls (via requests) – To communicate with the Databricks LLM endpoint for inference \n",
    "\n",
    "- Evaluation & Observability: Track latency, error rate, retrieval quality, and token/cost.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e194dde-26bc-4595-93ea-304433ba183c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe31eee-b0f7-49ff-9b7d-427218e42a8b/lib/python3.11/site-packages (5.1.2)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe31eee-b0f7-49ff-9b7d-427218e42a8b/lib/python3.11/site-packages (from sentence-transformers) (4.57.1)\nRequirement already satisfied: tqdm in /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe31eee-b0f7-49ff-9b7d-427218e42a8b/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe31eee-b0f7-49ff-9b7d-427218e42a8b/lib/python3.11/site-packages (from sentence-transformers) (2.9.0)\nRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.11/site-packages (from sentence-transformers) (1.3.0)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.11/site-packages (from sentence-transformers) (1.11.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe31eee-b0f7-49ff-9b7d-427218e42a8b/lib/python3.11/site-packages (from sentence-transformers) (0.36.0)\nRequirement already satisfied: Pillow in /databricks/python3/lib/python3.11/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: typing_extensions>=4.5.0 in /databricks/python3/lib/python3.11/site-packages (from sentence-transformers) (4.10.0)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe31eee-b0f7-49ff-9b7d-427218e42a8b/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\nRequirement already satisfied: packaging>=20.9 in /databricks/python3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.31.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe31eee-b0f7-49ff-9b7d-427218e42a8b/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe31eee-b0f7-49ff-9b7d-427218e42a8b/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\nRequirement already satisfied: networkx>=2.5.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe31eee-b0f7-49ff-9b7d-427218e42a8b/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\nRequirement already satisfied: jinja2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe31eee-b0f7-49ff-9b7d-427218e42a8b/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: numpy>=1.17 in /databricks/python3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.23.5)\nRequirement already satisfied: regex!=2019.12.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe31eee-b0f7-49ff-9b7d-427218e42a8b/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe31eee-b0f7-49ff-9b7d-427218e42a8b/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe31eee-b0f7-49ff-9b7d-427218e42a8b/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: joblib>=1.1.1 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe31eee-b0f7-49ff-9b7d-427218e42a8b/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-abe31eee-b0f7-49ff-9b7d-427218e42a8b/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2023.7.22)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# resume_summary_pipeline.py\n",
    "\n",
    "%pip install sentence-transformers\n",
    "\n",
    "from pathlib import Path\n",
    "import textwrap\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b74659dd-be47-4831-8a98-dd45d1f9d4fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### 1. Reading and Chunking Resume: \n",
    "\n",
    "LLMs perform better with concise inputs. We are chunking long resumes into small parts (~800 chars) to be later searched semantically using **read_chunk_resume** function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b2b685c-3f53-470a-a548-34472330d061",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import textwrap\n",
    "\n",
    "def read_and_chunk_resume(path, width=800):\n",
    "    text = Path(path).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    return textwrap.wrap(text, width=width)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9d4540c-77bf-4721-8713-984d18f1494f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Governance and Privacy - PII redaction: Masking name, organisation/emailaddress before retrieval is crucial for securing sensitive employee information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf459fcd-b725-4240-88b2-048aad4ef6c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def anonymize_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Redacts candidate names and company names using simple regex patterns.\n",
    "    \"\"\"\n",
    "    # Common company suffixes\n",
    "    company_pattern = re.compile(\n",
    "        r\"\\b[A-Z][A-Za-z&\\.\\- ]{1,30}\\s+(Inc|Ltd|LLC|Technologies|Solutions|Consulting|Corporation|Corp|Systems|Group|Company|Enterprises)\\b\",\n",
    "        flags=re.I\n",
    "    )\n",
    "\n",
    "    # Detect names (2 capitalized words like \"John Smith\")\n",
    "    name_pattern = re.compile(r\"\\b([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)+)\\b\")\n",
    "\n",
    "    text = company_pattern.sub(\"[COMPANY]\", text)\n",
    "    text = name_pattern.sub(\"[CANDIDATE]\", text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "233435e8-74db-4872-bd5f-317876d31e99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Path(path).read_text(),** Reads the content of the file at the specified path. \n",
    "\n",
    "**textwrap.wrap(text, width=800),** Splits the long resume string into chunks of **~800 characters** and which avoids cutting off, which improves token management for LLMs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0568c086-c88f-4646-91c9-4b97a5cc5239",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#####2.  Generating Embeddings:\n",
    "Embeddings converts chunks into high-dimensional vectors so we can find semantically similar text based on a query.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cddcf01-3c50-4dce-9de7-2191b74292f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def get_embeddings(chunks, model_name=\"all-MiniLM-L6-v2\"):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    embeddings = model.encode(chunks, normalize_embeddings=True)\n",
    "    return embeddings, model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74a6925b-269e-4c87-a580-ac121f59844c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The SentenceTransformer('all-MiniLM-L6-v2') model converts text chunks into dense numeric vectors (embeddings) that represent their meaning. The model.encode() function takes a list of text chunks and creates a 384-dimensional embedding for each one. This process returns two things:\n",
    "\n",
    "Embeddings – a list of vector representations for each text chunk.\n",
    "\n",
    "The model – which can be reused later to embed new text or queries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0eec0810-dc80-465f-8421-766c8528ee70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#####  3.Re-ranking using Cross Encoder to score and order the relevant chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9485bc6f-8bca-4801-9750-3f1b84c8777f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "def rerank_with_cross_encoder(query, candidate_pairs, cross_encoder_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\", top_k=3):\n",
    "    ce = CrossEncoder(cross_encoder_name)\n",
    "    pairs = [(query, txt) for _, txt in candidate_pairs]\n",
    "    scores = ce.predict(pairs)\n",
    "    order = np.argsort(-scores)[:top_k]\n",
    "    return [candidate_pairs[i][0] for i in order]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b110daa-83d2-450c-9004-a846d81dd479",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This function reranks text chunks based on their relevance to different queries  using a pre-trained CrossEncoder model.\n",
    "It pairs the query with each text chunk, predicts relevance scores, sorts them in descending order, and returns the indices of the top_k most relevant chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8459664-7ea0-4ce0-946d-1626521813c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_top_k_chunks(query, chunks, embeddings, model, top_k=5, use_cross_encoder=True, bi_encoder_candidates=10):\n",
    "    q_emb = model.encode([query], convert_to_numpy=True, normalize_embeddings=True)[0]\n",
    "    sims = cosine_similarity([q_emb], embeddings)[0]\n",
    "    cand_ids = np.argsort(-sims)[:max(top_k, bi_encoder_candidates)]\n",
    "    candidates = [(i, chunks[i]) for i in cand_ids]\n",
    "    if use_cross_encoder:\n",
    "        top_ids = rerank_with_cross_encoder(query, candidates, top_k=top_k)\n",
    "    else:\n",
    "        top_ids = list(cand_ids[:top_k])\n",
    "    return [chunks[i] for i in top_ids]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9c17c14-59dd-4c3c-9909-f85c7997ab64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The function first uses a bi-encoder to quickly find the most similar chunks to a query based on cosine similarity.\n",
    "Then, if enabled, it uses a cross-encoder to rerank those top candidates for higher accuracy before returning the best top_k chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efbe4d06-392c-4eaf-a82f-031edf712a3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e26c0cfe-8003-453c-95a6-fca5b07fa9f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Calling Databricks LLM endpoint LLAMA-4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0be43b20-6c5f-487c-91d3-d0ab387833c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def call_databricks_llm(prompt, model=\"databricks-llama-4-maverick\", max_tokens=500):\n",
    "    os.environ[\"DATABRICKS_HOST\"] = DATABRICKS_HOST\n",
    "    os.environ[\"DATABRICKS_TOKEN\"] = DATABRICKS_TOKEN\n",
    "\n",
    "    api_url = f\"{DATABRICKS_HOST}/serving-endpoints/{model}/invocations\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {os.environ['DATABRICKS_TOKEN']}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes resumes.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens\n",
    "    }\n",
    "\n",
    "    response = requests.post(api_url, headers=headers, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        r = response.json()\n",
    "        if \"predictions\" in r:\n",
    "            return r[\"predictions\"][0][\"message\"][\"content\"]\n",
    "        elif \"choices\" in r:\n",
    "            return r[\"choices\"][0][\"message\"][\"content\"]\n",
    "        elif \"data\" in r:\n",
    "            return r[\"data\"][\"message\"]\n",
    "        else:\n",
    "            raise Exception(f\"Unknown response structure: {r}\")\n",
    "    else:\n",
    "        raise Exception(f\"Request failed: {response.status_code} — {response.text}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ecdef29-bcfe-4f86-bba5-d8187016d70d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "This script interacts with a Databricks-hosted large language model (LLM) by sending a prompt and receiving a summarized response. The API URL is constructed dynamically using the model name to ensure the request reaches the correct endpoint.\n",
    "\n",
    "The payload follows the OpenAI-style chat format, which includes a system message to set the assistant's behavior and a user message containing the actual prompt. \n",
    "\n",
    "The max_tokens parameter is used to limit the length of the model's response, ensuring it remains concise and controlled. Finally, the requests.post() function is used to make the HTTP request, sending the payload and headers to the LLM endpoint and retrieving the generated output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9fc4e1b-0b86-4b41-8452-60f52ceb60b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Format Prompt with Prompt Engineering: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5153ad57-b99a-429d-b4ed-4e672001e697",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def format_prompt(context, query):\n",
    "    return f\"\"\"\n",
    "[System]\n",
    "You are a Resume Summarization Agent for hiring managers and recruiters.\n",
    "Your goal is to generate a relevance candidate summary aligned with Hiring Managers Expectations. \n",
    "\n",
    "[Rules]\n",
    "- Use ONLY the provided resume text. Do not hallucinate or make up content.\n",
    "- Output 5–6 bullets max. \n",
    "- Prioritize dated experience and measurable impact over skill lists.\n",
    "- Prefer recent (last 24 months) items when choosing examples.\n",
    "- No filler, no duplication, no assumptions.\n",
    "- Focus on relevance Job role (skills, experience, and Impact alignment).\n",
    "- If multiple roles or domains are present, highlight the most relevant one to the query.\n",
    "- Apply section weighting when selecting evidence and examples. Order of priority:\n",
    "  1) Experience (1.30x)\n",
    "  2) Education (1.10x)\n",
    "  3) Skills (0.90x)\n",
    "  4) Other (0.70x)\n",
    "- When in doubt, pick items from higher-weight sections; include lower-weight sections only if they clearly strengthen relevance to the query and Job Desciption. \n",
    "\n",
    "[Output format]\n",
    "• Experience & Domain: <Years> across <key domains>; recent roles at <2 most recent companies/titles>.\n",
    "• Tech Stack: Mention only what appears in the resume.\n",
    "• Responsibilities/Projects:  4 aligned tasks, if present. \n",
    "  Impact Highlights:   2–3 short clauses with numbers.\n",
    "• Risks/Notes:   gaps >6mo and roles <12months\n",
    "• Relevance Summary: Overall fit to the query/Job (High / Medium / Low).\n",
    "\n",
    "[Resume]\n",
    "{context}\n",
    "\n",
    "[Task]\n",
    "\"{query}\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe2c6b92-1e74-4230-afef-f40a5f718075",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "_relevance_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def relevance_score(summary, context_chunks):\n",
    "    summary_emb = _relevance_model.encode([summary], normalize_embeddings=True)\n",
    "    context_emb = _relevance_model.encode([\" \".join(context_chunks)], normalize_embeddings=True)\n",
    "    cos = float(cosine_similarity(summary_emb, context_emb)[0][0])\n",
    "\n",
    "\n",
    "    score = max(0.0, min(1.0, cos))\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5bfa6fd-bfa9-40a9-acd9-a5a36915fe44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def summarize_resume(file_path_txt, query):\n",
    "    chunks = read_and_chunk_resume(file_path_txt)\n",
    "    embeddings, model = get_embeddings(chunks)\n",
    "    top_chunks = get_top_k_chunks(query, chunks, embeddings, model)\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "    prompt = format_prompt(context, query)\n",
    "    summary = call_databricks_llm(prompt, max_tokens=600)\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c673d201-1682-43bc-a4ca-879441fa4d45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This function computes how relevant a generated summary is to the original context using a semantic similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dc4ccd2-fd30-4a64-b9a2-8cdb88654025",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def summarize_all_resumes(file_paths, query):\n",
    "    results = []\n",
    "    errors = 0\n",
    "    total_time = 0\n",
    "    relevance_scores = []\n",
    "\n",
    "    for path in file_paths:\n",
    "        start = time.time()\n",
    "        try:\n",
    "            result = summarize_resume(path, query)\n",
    "            result_text = result if isinstance(result, str) else result[0]\n",
    "            relevance = relevance_score(result_text, read_and_chunk_resume(path))\n",
    "            results.append((path, result_text, relevance))\n",
    "            relevance_scores.append(relevance)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error on {path}: {e}\")\n",
    "            errors += 1\n",
    "        total_time += time.time() - start\n",
    "\n",
    "    avg_latency = total_time / len(file_paths)\n",
    "    avg_rel = np.mean(relevance_scores)\n",
    "    err_rate = errors / len(file_paths)\n",
    "\n",
    "    print(\"\\n### **Evaluation Summary**\")\n",
    "    print(\"| Metrics | \")\n",
    "    print(f\"| Average Latency: | {avg_latency:.2f} sec/resume |\")\n",
    "    print(f\"| Error Rate: | {err_rate*100:.1f}% |\")\n",
    "    print(f\"| Average Relevance Score: | {avg_rel:.2f} |\")\n",
    "\n",
    "\n",
    "    # Sort by relevance so best ones come first\n",
    "    results.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    for path, summary, rel in results:\n",
    "        name = Path(path).stem\n",
    "        print(f\"\\n---\\n#### {name} — Relevance: {rel:.2f}\")\n",
    "        print(summary.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7c9f33d-f907-4509-ad6a-2d6c6296dbbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This function loops through multiple resumes, summarizes each one using your summarize_resume() function, then measures:\n",
    "\n",
    "- Latency (how long each took)\n",
    "- Error rate, and\n",
    "- Average relevance (how semantically similar each summary is to its original resume, via your relevance_score() function). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d6c19f2-5821-4366-b3bf-17473715aa0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n### **Evaluation Summary**\n| Metrics | \n| Average Latency: | 5.25 sec/resume |\n| Error Rate: | 0.0% |\n| Average Relevance Score: | 0.59 |\n\n---\n#### Sakshi_Gundawar — Relevance: 0.66\nHere is a summary of the resume in the required format:\n\n• Experience & Domain: 6+ years across healthcare, telecom, and e-commerce sectors; recent roles at Data Analyst positions.\n• Tech Stack: Python, R, Java, Py Spark, TensorFlow, Scikit-learn, PostgreSQL, MySQL, MongoDB, Tableau, Excel, Power BI, Looker, Google Data Studio, Google Cloud, AWS (Lambda, S3, EC2).\n• Responsibilities/Projects: \n  - Applied predictive modeling and statistical analysis to drive business insights.\n  - Developed real-time dashboards using Tableau and Power BI.\n  - Engineered data validation pipelines using Python and SQL.\n  - Conducted customer retention analysis and built customer segmentation models.\n• Impact Highlights: \n  - Improved patient retention by 30% through optimized trial design.\n  - Reduced manual reporting by 60% and accelerated decision cycles by 2 days.\n  - Improved data quality by 99% through outlier detection.\n• Risks/Notes: No apparent gaps >6mo; most recent role lasted 4+ years.\n• Relevance Summary: High (given the strong alignment with data analyst roles, showcasing relevant technical skills, and significant impact in previous positions).\n\n---\n#### Haiming Wang — Relevance: 0.57\nHere is a summary of the provided resume in the requested format:\n\n• **Experience & Domain**: 20+ years across Econometrics, Finance, and Risk Management; recent roles at CitiGroup (Modeling Specialist, Business Analyst).\n• **Tech Stack**: SAS, SAS Enterprise Miner, R, Revolution R, Python, AI/ML, BI tools.\n• **Responsibilities/Projects**:\n  • Developed credit risk models for acquisitions and existing customers.\n  • Conducted predictive modeling and data analysis for credit default and customer behavior.\n  • Performed model validations and analyses for regulatory and model governance.\n  • Applied statistical and econometric analysis for credit scoring and risk assessment.\n• **Impact Highlights**:\n  • Developed models for fraud detection, collection, and customer behavior.\n  • Conducted credit value at risk analysis for mortgage-backed securities.\n• **Risks/Notes**: Gaps in employment > 6 months between roles.\n• **Relevance Summary**: High (Strong background in Econometrics, Finance, and Risk Management with relevant technical skills).\n\n---\n#### Raja_Agarwal — Relevance: 0.56\nHere is a summary of the resume in the required format:\n\n• Experience & Domain: 5+ years across Data Science and Analytics, Retail, and Strategy; recent roles at Tesco as Lead Data Science Consultant and Senior Data Science Consultant.\n• Tech Stack: Python, SQL, Microsoft Office Suite (PowerPoint, Excel, and Word), Data Visualization (Tableau), Azure openAI, Llama3.\n• Responsibilities/Projects: \n  - Led a team to develop a Generative AI-powered news app, decommissioning ~50 dashboards.\n  - Coordinated with leadership to mitigate low online profitability by removing 100 underperforming products.\n  - Pioneered an in-house forecasting framework, improving accuracy from 92% to 98%.\n  - Automated customer review analysis using LLMs, generating a direct benefit of ~£100K annually.\n• Impact Highlights: \n  - Mitigated ~£25M annual losses by removing underperforming products.\n  - Improved forecast accuracy from 92% to 98%.\n  - Generated a direct benefit of ~£100K annually through automated customer review analysis.\n• Risks/Notes: No gaps >6mo; one role <2 years (Data Science Consultant, 1 year 2 months).\n• Relevance Summary: High. The candidate has relevant experience in data science, analytics, and strategy, with measurable impact in their recent roles.\n\n---\n#### Kayuri Shah — Relevance: 0.55\nHere is a summarized version of the resume in the required format:\n\n• **Experience & Domain**: 4+ years across Data Science, Machine Learning, and Financial Analytics; recent roles at Mastercard and Mu Sigma.\n• **Tech Stack**: Python, SQL, R, Microsoft Azure, GCP, AWS, Tableau, Power BI.\n• **Responsibilities/Projects**: \n  - Analyzed interchange-based card segments to identify factors causing low interchange rates.\n  - Implemented demand forecasting models for inventory management.\n  - Built propensity models using XGBoost and Random Forest.\n  - Conducted customer segmentation analysis and developed acquisition and retention strategies.\n• **Impact Highlights**: \n  - Reduced order cycle time by 75% through demand forecasting.\n  - Increased conversion rates by 14% and reduced turnaround time by 80% through audience optimization.\n  - Achieved a 17% revenue lift in 3 months through CLV-driven campaign.\n• **Risks/Notes**: No gaps >6mo; one role <2y (Decision Scientist, 3.5 years).\n• **Relevance Summary**: High (Strong experience in Data Science, Machine Learning, and Financial Analytics, with measurable impact and relevant tech stack).\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    resumes = [\n",
    "        \"/Volumes/workspace/default/default_resume/Haiming Wang.txt\",\n",
    "        \"/Volumes/workspace/default/default_resume/Kayuri Shah.txt\",\n",
    "        \"/Volumes/workspace/default/default_resume/Raja_Agarwal.txt\",\n",
    "        \"/Volumes/workspace/default/default_resume/Sakshi_Gundawar.txt\",\n",
    "    ]\n",
    "\n",
    "    query = \" Hide candidate organization and Name, summaries resume\"\n",
    "    summarize_all_resumes(resumes, query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06fdb1f8-3734-4a1b-8f12-72c8e550dee7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Future Work: \n",
    "\n",
    "2. Creating a Front End UI for Hiring Managers which will integrate with ATS and have options for them to write query, see summaries and download only relevant resumes. \n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Resume_Summarizer_ Agent_Pipeline_RAG +LLaMa + Transformers ",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}